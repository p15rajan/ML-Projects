#Airline Passenger  Satisfaction 
# Importing Required Libraries

import pandas as pd
import numpy as np 
import seaborn as sns
sns.set()
import matplotlib.pyplot as plt
import os, sys
import warnings 
warnings.filterwarnings("ignore")

#Reading the data file 
df = pd.read_csv("airline_passenger_satisfaction.csv")

#Printing the first 5 rows of the data
df.head()

# Printing the details of the DataFrame
df.info()

# Finding the details and number of the Customers
df['Customer Type'].value_counts()


# Mathematical & Statistical Information 
df.describe()

# Finding the null values 
df.isnull().sum()

# Finding the duplicated values 
df.duplicated().sum()


# Displaying the Columns
df.columns

# Imputation of Null values with Median
df['Arrival Delay'] = df['Arrival Delay'].fillna(df['Arrival Delay'].median())

# Checking the null values after Imputation 
df.isnull().sum()


Automated EDA 
from dataprep.eda import create_report
create_report(df).show()


# To find out the Imbalanced data
df['Satisfaction'].value_counts() # Data is balanced 


# Dropping unnecessary Variables
df1 = df.drop(['ID','Satisfaction'], axis=1)

df1.info()

df_new = df.drop(['ID','Gate Location', 'Leg Room Service', ], axis=1)

df_new.head()

df_new.info()

# Encoding the Object variables as the variables are Object variables
   
df_new = pd.get_dummies(df_new, columns=['Customer Type','Class', 'Gender', 'Type of Travel'])  

df_new.head()



#Feature Selection - Defining Independent and Dependent variables 
X = df_new.drop(['Satisfaction'], axis=1)

# To find out the details of X variable.
X.shape

Y=df_new['Satisfaction']
arr1 = np.array(Y)

# Convert the array to One Dimension 
arr2 = arr1.reshape(-1,1)
arr2

Y = pd.DataFrame(arr2,).reset_index
print(Y)

# Label Encoding the Target variable 
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
Y = encoder.fit_transform(arr2)
print(Y)


# Encoding the Class
df_new['Class_Economy Plus'].value_counts()

# Data Visuzalzation 
for i in X:
    plt.figure()
    plt.tight_layout()
    sns.set(rc={"figure.figsize":(3, 3)})
    f, (ax_box) = plt.subplots(1, sharex=True)
    f, (ax_hist) = plt.subplots(1, sharex=True)
    plt.gca().set(xlabel=i,ylabel='Satisfaction')
    sns.boxplot(X[i], hue=Y,ax=ax_box , linewidth= 1.0)
    sns.histplot(X[i], ax=ax_hist , bins = 10,kde=True) 

# Standardization of the variables. 

from sklearn.preprocessing import StandardScaler
Scaler = StandardScaler()

X_Scaled = Scaler.fit_transform(X)

# Splitting the train and test variables 
from sklearn.model_selection import train_test_split

X_train, X_test,Y_train,Y_test = train_test_split(X_Scaled,Y, test_size=0.2, random_state=42)

# Importing various Libraries for Model Building 
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC 
from xgboost import XGBClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix,classification_report,f1_score


# Model Building 

# ### Logistic Regression 
print("\033[5m"+ "LOGISTIC REGRESSION" + "\033[0m\n")
Log = LogisticRegression()
Log.fit(X_train,Y_train)


# ### Random Forest Classifier 
print("\033[5m"+ "RANDOM FOREST" +"\033[0m\n")
RF = RandomForestClassifier()
RF.fit(X_train,Y_train)


# ### Decision Tree Classifier
print("\033[5m"+ "DECISION TREE CLASSIFIER"+ "\033[0m\n")
DT = DecisionTreeClassifier()
DT.fit(X_train,Y_train)


# ### Naive Bayes Theorem

print("\033[5m"+ "NAIVE BAYES CLASSIFIER"+"\033[0m\n")
NB = GaussianNB()
NB.fit(X_train,Y_train)


# ### Support Vector Machine
print("\033[5m"+ "SUPPORT VECTOR MACHINE"+"\033[0m\n")
SVM = SVC()
SVM.fit(X_train,Y_train)


# ### XGboost Classifier 
print("\033[5m"+ "XGBOOST CLASSIFIER"+"\033[0m\n")
Xg =  XGBClassifier()
Xg.fit(X_train,Y_train)


# ### Stochastic gradient descient (SGD)ÔÉÅ

#from sklearn.calibration import CalibratedClassifierCV
#calibrator = CalibratedClassifierCV(ClfSGD, cv='prefit')
#calibrator.fit(X_train,Y_train)


print("\033[5m"+ "Stochastic Boost Classifier"+"\033[0m\n")
SGD =  SGDClassifier(loss='hinge', alpha=0.0001, class_weight='balanced')
SGD.fit(X_train,Y_train)


# ### Adaboost Classifier
print("\033[5m"+ "Ada Boost Classifier"+"\033[0m\n")
AB = AdaBoostClassifier()
AB.fit(X_train,Y_train)

#Model_com_df=pd.DataFrame(Model_comparison).T
#Model_com_df.pop(3)
#Model_com_df.columns=['Model Accuracy','Model F1-Score','CV Accuracy']
#Model_com_df=Model_com_df.sort_values(by='Model F1-Score',ascending=False)
#Model_com_df.style.format("{:.2%}").background_gradient(cmap='Blues')
##Model_com_df.style.format("{:.2%}")

# Calcualation the Accuracy Score, f1_score, roc_auc_score, precsion and recall score and Testing the Model 
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef,     roc_auc_score,precision_score, recall_score,     average_precision_score

# Model Comparision 
def get_scoring_functions():
    cfuncs = [accuracy_score, f1_score, matthews_corrcoef, recall_score]
    pfuncs = [roc_auc_score, average_precision_score]
    return cfuncs, pfuncs

def get_tuple_cols():
    cfuncs, pfuncs = get_scoring_functions()
    return ['model'] + [f.__name__ for f in cfuncs] + [f.__name__ for f in pfuncs]

def get_scores(model_name, y_true, y_preds):
    cfuncs, pfuncs = get_scoring_functions()

    cscores = {f.__name__: f(y_true, y_preds) for f in cfuncs}
    pscores = {f.__name__: f(y_true, y_preds) for f in pfuncs}

    d = {**cscores, **pscores}
    d['model'] = model_name

    return tuple([d[c] for c in get_tuple_cols()])

models = [Log,RF, DT, NB, SVM, Xg, SGD, AB]
model_names = [type(m).__name__ for m in models]

y_preds = {type(model).__name__: model.predict(X_test) for model in models}
#y_probs = {type(model).__name__: model.predict_proba(X_test)[:,1] for model in models}
scores = [get_scores(name, Y_test, y_preds[name]) for name in model_names]
df = pd.DataFrame(scores, columns=get_tuple_cols())
df=df.sort_values('f1_score',ascending=False).reset_index(drop=True)
df=df.style.background_gradient(cmap='viridis')
df
